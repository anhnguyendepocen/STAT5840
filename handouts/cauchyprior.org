#+TITLE:   Bayesian Monte Carlo Computations
#+AUTHOR:    G. Jay Kerns
#+EMAIL:     gkerns@ysu.edu
#+DATE:      STAT 5840: Summer 2011
#+OPTIONS:   H:4 toc:nil author:nil ^:nil num:nil f:nil
#+BABEL: :session *R* :results output pp :tangle yes
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [11pt,english]
#+LATEX_HEADER: \input{handoutformat}
#+latex: \thispagestyle{empty}

* Estimating a Normal mean with a Cauchy Prior
We would like to illustrate using the Monte Carlo method to estimate complicated integrals in Bayesian applications.  The following is a script which estimates the mean of a Normal distribution when our prior distribution is Cauchy.

#+begin_src R :exports code
# cauchyprior.R
set.seed(1) # make the experiment reproducible
m <- 2000   # number of simulated values
x <- 3      # observed data

# Now simulate some random variables
theta <- rcauchy(m) # simulate m standard Cauchys
h <- pi*exp(-0.5*(x-theta)^2)  # compute h(theta)

C <- mean(h)  # estimate the normalizing constant
post.mean <- mean(theta*h)/mean(h) # estimate the posterior mean

# We'd like to see a running average plot to assess convergence

num <- theta*h   # vector in the numerator
rc <- rep(0, times = m)
rpm <- rep(0, times = m)

for (i in seq.int(m)){         # seq.int(m) will be 1:m
  rc[i] <- mean(h[1:i])
  rpm[i] <- mean(num[1:i])/mean(h[1:i])
}
#+end_src

* At the command prompt

#+begin_src R :exports both
C
post.mean
#+end_src

The true values are \(C \approx 0.34168057 \) and \(\mbox{Posterior Mean} = 2.284967653\).

#+CAPTION:    Running averages for assessing convergence of the estimators
#+LABEL:      fig:yplot
#+ATTR_LaTeX: width=6in, height=6in, placement=[h!]
#+begin_src R :exports both :results output graphics :file img/CauchyPrior.pdf
# now plot the results
par(mfrow = c(1,2))
plot(3:200, rpm[3:200], type = "l", ylim = c(0, 2.7))
lines(3:200, rc[3:200], type = "l")
plot(1:m, rpm, type = "l", ylim = c(0, 2.7))
lines(1:m, rc, type = "l")
par(mfrow = c(1,1))
#+end_src
